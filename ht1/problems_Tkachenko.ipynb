{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = np.array(sample[\"msg\"]), np.array(sample[\"target\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        if category_priors is None:\n",
    "            self.category_priors = defaultdict(int)\n",
    "        else:\n",
    "            self.category_priors = category_priors\n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "\n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(Counter)\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "    \n",
    "    # Токенизируем, если нужно \n",
    "    def tokenize(self, text):\n",
    "        if not isinstance(text, list):\n",
    "            text = np.array(text.split(' '))\n",
    "        return np.array(text)\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        \n",
    "        # Список категорий\n",
    "        self.cats = np.unique(y_train)\n",
    "        \n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        \n",
    "        for y in y_train:\n",
    "            self.category_doc_counts[y] += 1\n",
    "            \n",
    "        for idx, x in enumerate(x_train):\n",
    "            for word in np.unique(self.tokenize(x)):\n",
    "                self.feature_counts[word] += 1\n",
    "                self.feature_category_counts[y_train[idx]][word] += 1\n",
    "                \n",
    "        self.category_counts = Counter()\n",
    "        for cat in self.cats:\n",
    "            for elem in self.feature_category_counts[cat]:\n",
    "                self.category_counts[cat] += self.feature_category_counts[cat][elem]\n",
    "\n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их\n",
    "        if len(self.category_priors) == 0:\n",
    "            for cat in np.unique(y_train):\n",
    "                self.category_priors[cat] = len(np.argwhere(y_train == cat)) / len(y_train)\n",
    "                \n",
    "        # Число всех слов\n",
    "        sm = 0\n",
    "        for elem in self.feature_counts:\n",
    "            sm += self.feature_counts[elem]\n",
    "        self.all_features = sm\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        return self.cats[np.argmax(self.get_probs(text))]\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : float\n",
    "            Точность предсказания.\n",
    "        \"\"\"\n",
    "        \n",
    "        res = 0\n",
    "        for idx, x in enumerate(text):\n",
    "            res += self.predict(x) == labels[idx]\n",
    "            \n",
    "        acc = res / len(labels)\n",
    "            \n",
    "        return acc\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        \n",
    "        probs = [self.get_category_prob(cat, text) for cat in self.cats]\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятность принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        text = self.tokenize(text)\n",
    "        \n",
    "        log_prob = np.log(self.category_priors[cat])\n",
    "        for word in text:\n",
    "                pr = self.get_weighted_feature_prob(cat, word)\n",
    "                if pr == 0:\n",
    "                    pr = self.supposed_prob\n",
    "                log_prob += np.log(pr)\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        \n",
    "        prob = (self.feature_category_counts[cat][feature] /self.category_counts[cat]\n",
    "                + self.weight * self.feature_counts[feature] / self.all_features) / (self.weight + 1)\n",
    "\n",
    "        return prob\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat : list of str\n",
    "        \"\"\"\n",
    "        return self.cats\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "all_words = {}\n",
    "\n",
    "def prepare_train_for_nltk(X, y):\n",
    "    train = np.column_stack((X, y))\n",
    "    t = []\n",
    "    all_words = set(word.lower() for passage in train for word in passage[0].split(\" \"))\n",
    "    for x in tqdm.tqdm(train):\n",
    "        t.append(({word: (word in x[0].split(\" \")) for word in all_words}, x[1]))\n",
    "    #t = [({word: (word in x[0].split(\" \")) for word in all_words}, x[1]) for x in train]\n",
    "    return t, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2893/2893 [1:32:59<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "res = prepare_train_for_nltk(X, y)\n",
    "transformed_data, all_words = res[0], res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_data = np.array(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [39:16, 235.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "kf = KFold(n_splits=10, random_state=47)\n",
    "\n",
    "scores_nltk, scores_mine = [], []\n",
    "\n",
    "for train_index, test_index in tqdm.tqdm(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    nb_mine = NaiveBayes(weight=0.1, supposed_prob=0.6)\n",
    "    nb_nltk = NaiveBayesClassifier.train(np_data[train_index])\n",
    "    nb_mine.fit(X_train, y_train)\n",
    "    scores_mine.append(nb_mine.score(X_test, y_test))\n",
    "    scores_nltk.append(accuracy_score([nb_nltk.classify(featureset=t) for t in np_data[test_index, 0]], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x227e5d3d518>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJakh/x9MyAWSWzZI3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227f1f8bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_nltk = pd.DataFrame(scores_nltk)\n",
    "df_mine = pd.DataFrame(scores_mine)\n",
    "ax = df_nltk.boxplot()\n",
    "df_mine.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вывод: ** Как видно из диаграммы разбросов выше, наш классификатор более точен и обучается заметно быстрее (2 секунды против 4 минут)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
